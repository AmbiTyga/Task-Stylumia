{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-Training and Testing",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmbiTyga/Task-Stylumia/blob/Basic/Model-Training_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASqB2wYxxZQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61dd5d76-b0d2-49c5-b8a8-a2d877089a34"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/AmbiTyga/Task-Stylumia/Basic/TrainTest.7z"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-28 15:31:04--  https://raw.githubusercontent.com/AmbiTyga/Task-Stylumia/Basic/TrainTest.7z\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9147130 (8.7M) [application/octet-stream]\n",
            "Saving to: ‘TrainTest.7z’\n",
            "\n",
            "TrainTest.7z        100%[===================>]   8.72M  29.5MB/s    in 0.3s    \n",
            "\n",
            "2021-02-28 15:31:05 (29.5 MB/s) - ‘TrainTest.7z’ saved [9147130/9147130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh4t8ETbx_u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3204fc05-94a9-4560-9a27-6f6da0a48375"
      },
      "source": [
        "!7z x TrainTest.7z"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 9147130 bytes (8933 KiB)\n",
            "\n",
            "Extracting archive: TrainTest.7z\n",
            "--\n",
            "Path = TrainTest.7z\n",
            "Type = 7z\n",
            "Physical Size = 9147130\n",
            "Headers Size = 194\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 26% 1 - train_parsed.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 1 - train_parsed.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% 2\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 2\n",
            "Size:       109002701\n",
            "Compressed: 9147130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psECtCenyDMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6c1072-d6bf-4000-a25e-db37e27b2e80"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import torch \r\n",
        "from torchtext import data\r\n",
        "from torchtext.vocab import GloVe\r\n",
        "import torch.nn as nn\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "STOPWORDS = stopwords.words('english')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0geNMvkiCZx"
      },
      "source": [
        "train = pd.read_json('/content/train_parsed.json')\r\n",
        "test = pd.read_json('/content/test_parsed.json')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtN8oszHIFjg"
      },
      "source": [
        "def padding(text,attr = 'title'):\r\n",
        "  max_len = 39 if attr=='title' else 282\r\n",
        "  sent_len = len(text.split())\r\n",
        "  if sent_len>max_len:\r\n",
        "    return \" \".join(text.split()[:max_len])\r\n",
        "  else:\r\n",
        "    text = \" \".join(text.split()+['<pad>']*(max_len-sent_len))\r\n",
        "    return text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFhq5ommic5S"
      },
      "source": [
        "train.drop(columns=['tld_with_tok', 'ac_tok','title_tok', 'body_tok', 'text', 'raw_text'],inplace = True)\r\n",
        "test.drop(columns=['tld_with_tok', 'ac_tok','title_tok', 'body_tok', 'text', 'raw_text'],inplace = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLlhvwrpOr5F"
      },
      "source": [
        "train['text'] = '<tld> '+ train['tld']+ ' <ac> ' + train['alchemy_category'] + ' <title> ' + train['title'].apply(padding)+ ' <body> ' + train['body'].apply(padding,attr='body') \r\n",
        "test['text'] = '<tld> '+ test['tld']+ ' <ac> ' + test['alchemy_category'] + ' <title> ' + test['title'].apply(padding)+ ' <body> ' + test['body'].apply(padding,attr='body') "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrZDvIZXL2Cj"
      },
      "source": [
        "train['text'] = train['text'].apply(lambda x: \" \".join([y for y in x.split() if y not in STOPWORDS]).lower())\r\n",
        "test['text'] = test['text'].apply(lambda x: \" \".join([y for y in x.split() if y not in STOPWORDS]).lower())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Fo08pASffw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "Train,Val = train_test_split(train,random_state = 2021,test_size = 0.2,stratify = train['label'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gth54lTdS9yd"
      },
      "source": [
        "Train.to_csv('train.csv',index= False)\r\n",
        "Val.to_csv('val.csv',index= False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ypwJeGM6B9t",
        "outputId": "3e9998ab-84f9-4fff-8157-9f15ac31ff0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pytorch-nlp -q"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▋                            | 10kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xEOHd_e51a5"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWqtVkTIHU6T"
      },
      "source": [
        "import requests\r\n",
        "\r\n",
        "def download_file_from_google_drive(id, destination):\r\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\r\n",
        "\r\n",
        "    session = requests.Session()\r\n",
        "\r\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\r\n",
        "    token = get_confirm_token(response)\r\n",
        "\r\n",
        "    if token:\r\n",
        "        params = { 'id' : id, 'confirm' : token }\r\n",
        "        response = session.get(URL, params = params, stream = True)\r\n",
        "\r\n",
        "    save_response_content(response, destination)    \r\n",
        "\r\n",
        "def get_confirm_token(response):\r\n",
        "    for key, value in response.cookies.items():\r\n",
        "        if key.startswith('download_warning'):\r\n",
        "            return value\r\n",
        "\r\n",
        "    return None\r\n",
        "\r\n",
        "def save_response_content(response, destination):\r\n",
        "    CHUNK_SIZE = 32768\r\n",
        "\r\n",
        "    with open(destination, \"wb\") as f:\r\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\r\n",
        "            if chunk: # filter out keep-alive new chunks\r\n",
        "                f.write(chunk)\r\n",
        "\r\n",
        "download_file_from_google_drive('1KfiHaW7Ei31VSmi7gqfSdegTjHB8xuAm', '/content/glove.840B.300d.zip')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46HFFQavDz1Z"
      },
      "source": [
        "def load_embed(file):\r\n",
        "  '''\r\n",
        "  Loads GLoVe embeddings\r\n",
        "  file -> path to glove embeddings\r\n",
        "  load_embed(...) -> Dict()\r\n",
        "  '''\r\n",
        "  def get_coefs(word,*arr): \r\n",
        "      return word, torch.from_numpy(np.array(arr,dtype=np.float32))\r\n",
        "  \r\n",
        "  embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='utf-8'))\r\n",
        "      \r\n",
        "  return embeddings_index"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCsL94heGnfM",
        "outputId": "e62b3b73-ce19-4b4a-b976-3c8c32631fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip '/content/glove.840B.300d.zip'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTiirvGFjkpK"
      },
      "source": [
        "from torchnlp.encoders.text import StaticTokenizerEncoder, pad_tensor\r\n",
        "\r\n",
        "class MultiModalDataset(torch.utils.data.Dataset):\r\n",
        "  def __init__(self,data):\r\n",
        "    self.features = ['alchemy_category_score', 'alchemy_labels', 'avglinksize',\r\n",
        "       'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3',\r\n",
        "       'commonlinkratio_4', 'compression_ratio', 'embed_ratio',\r\n",
        "       'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio',\r\n",
        "       'is_news', 'lengthyLinkDomain', 'linkwordscore',\r\n",
        "       'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url',\r\n",
        "       'parametrizedLinkRatio', 'spelling_errors_ratio']\r\n",
        "    self.data = data\r\n",
        "    self.flag = train\r\n",
        "    \r\n",
        "    self.tokenizer = StaticTokenizerEncoder(data['text'].values, tokenize=lambda s: s.split())\r\n",
        "    \r\n",
        "  def __getitem__(self,i):\r\n",
        "    text = pad_tensor(self.tokenizer.encode(self.data.loc[i,'text']),length=328)\r\n",
        "    X = self.data.loc[i,self.features].astype(float).values\r\n",
        "    y = self.data.loc[i,'label']\r\n",
        "\r\n",
        "    return text,torch.FloatTensor(X),y\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.data)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPiloJHXaX0h",
        "outputId": "45d254fb-fe82-4a8d-af76-3042fbd3c4a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.loc[0,['label']].astype(float).values"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUv8CgwXNou0"
      },
      "source": [
        "total_data = pd.concat([pd.read_csv('/content/train.csv'),\r\n",
        "                        pd.read_csv('/content/val.csv')],ignore_index = True)\r\n",
        "all = MultiModalDataset(total_data)\r\n",
        "word_index = all.tokenizer.token_to_index\r\n",
        "del all, total_data"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdEg0wLtFr_V"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\r\n",
        "train_data = MultiModalDataset(train)\r\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,batch_size=32)\r\n",
        "\r\n",
        "val = pd.read_csv('/content/val.csv')\r\n",
        "val_data = MultiModalDataset(val)\r\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,batch_size=32)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRAqsJ40P916"
      },
      "source": [
        "embeddings_index = load_embed('glove.840B.300d.txt')\r\n",
        "\r\n",
        "EMBEDDING_DIM = 300\r\n",
        "embedding_matrix = torch.zeros((len(word_index) + 1, EMBEDDING_DIM))\r\n",
        "for word, i in word_index.items():\r\n",
        "    embedding_vector = embeddings_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "        # words not found in embedding index will be all-zeros.\r\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me3RY0aGhCoy"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.nn import functional as F\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class AttentionModel(torch.nn.Module):\r\n",
        "  def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\r\n",
        "    super(AttentionModel, self).__init__()\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Arguments\r\n",
        "    ---------\r\n",
        "    batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\r\n",
        "    output_size : 2 = (pos, neg)\r\n",
        "    hidden_sie : Size of the hidden_state of the LSTM\r\n",
        "    vocab_size : Size of the vocabulary containing unique words\r\n",
        "    embedding_length : Embeddding dimension of GloVe word embeddings\r\n",
        "    weights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \r\n",
        "\r\n",
        "    --------\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.output_size = output_size\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.vocab_size = vocab_size\r\n",
        "    self.embedding_length = embedding_length\r\n",
        "\r\n",
        "    self.numerical = nn.Sequential(\r\n",
        "        nn.Linear(21,128),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(128,128),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(128,64),\r\n",
        "        nn.ReLU()\r\n",
        "    )\r\n",
        "    \r\n",
        "    self.dropout = nn.Dropout(0.45)\r\n",
        "\r\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\r\n",
        "    self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\r\n",
        "    self.lstm = nn.LSTM(embedding_length, hidden_size)\r\n",
        "    self.label = nn.Linear(hidden_size+64, output_size)\r\n",
        "    #self.attn_fc_layer = nn.Linear()\r\n",
        "    \r\n",
        "  def attention_net(self, lstm_output, final_state):\r\n",
        "\r\n",
        "    \"\"\" \r\n",
        "    Now we will incorporate Attention mechanism in our LSTM model. In this new model, we will use attention to compute soft alignment score corresponding\r\n",
        "    between each of the hidden_state and the last hidden_state of the LSTM. We will be using torch.bmm for the batch matrix multiplication.\r\n",
        "\r\n",
        "    Arguments\r\n",
        "    ---------\r\n",
        "\r\n",
        "    lstm_output : Final output of the LSTM which contains hidden layer outputs for each sequence.\r\n",
        "    final_state : Final time-step hidden state (h_n) of the LSTM\r\n",
        "\r\n",
        "    ---------\r\n",
        "\r\n",
        "    Returns : It performs attention mechanism by first computing weights for each of the sequence present in lstm_output and and then finally computing the\r\n",
        "          new hidden state.\r\n",
        "          \r\n",
        "    Tensor Size :\r\n",
        "          hidden.size() = (batch_size, hidden_size)\r\n",
        "          attn_weights.size() = (batch_size, num_seq)\r\n",
        "          soft_attn_weights.size() = (batch_size, num_seq)\r\n",
        "          new_hidden_state.size() = (batch_size, hidden_size)\r\n",
        "            \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    hidden = final_state.squeeze(0)\r\n",
        "    attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\r\n",
        "    soft_attn_weights = F.softmax(attn_weights, 1)\r\n",
        "    new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\r\n",
        "\r\n",
        "    return new_hidden_state\r\n",
        "\r\n",
        "  def forward(self, inputs,X, batch_size=None):\r\n",
        "\r\n",
        "    \"\"\" \r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    input_sentence: input_sentence of shape = (batch_size, num_sequences)\r\n",
        "    batch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    Output of the linear layer containing logits for pos & neg class which receives its input as the new_hidden_state which is basically the output of the Attention network.\r\n",
        "    final_output.shape = (batch_size, output_size)\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    input = self.word_embeddings(inputs)\r\n",
        "    # print(input.shape)\r\n",
        "    input = input.permute(1, 0, 2)\r\n",
        "    if batch_size is None:\r\n",
        "      h_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\r\n",
        "      c_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\r\n",
        "    else:\r\n",
        "      h_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\r\n",
        "      c_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\r\n",
        "      \r\n",
        "    output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0)) # final_hidden_state.size() = (1, batch_size, hidden_size) \r\n",
        "    output = output.permute(1, 0, 2) # output.size() = (batch_size, num_seq, hidden_size)\r\n",
        "\r\n",
        "    attn_output = self.attention_net(output, final_hidden_state)\r\n",
        "\r\n",
        "    numericals = self.numerical(X)\r\n",
        "    numericals = self.dropout(numericals)\r\n",
        "    cat = torch.cat((attn_output, numericals), dim=1)\r\n",
        "    logits = self.label(cat)\r\n",
        "\r\n",
        "    return logits"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "VG0BdgsahJ4q",
        "outputId": "d562ac7b-7d65-4f62-f863-b7baaa733fe4"
      },
      "source": [
        "def clip_gradient(model, clip_value):\r\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\r\n",
        "    for p in params:\r\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\r\n",
        "\r\n",
        "def binary_acc(y_pred, y_test):\r\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\r\n",
        "    \r\n",
        "    print(y_pred ,y_test ,sep = ' -> ')\r\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\r\n",
        "    acc = correct_results_sum/y_test.shape[0]\r\n",
        "    acc = torch.round(acc * 100)\r\n",
        "    \r\n",
        "    return acc\r\n",
        "    \r\n",
        "def train_model(model, train_iter, epoch):\r\n",
        "    total_epoch_loss = 0\r\n",
        "    total_epoch_acc = 0\r\n",
        "    model.cuda()\r\n",
        "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\r\n",
        "    steps = 0\r\n",
        "    model.train()\r\n",
        "    for idx, batch in enumerate(train_iter):\r\n",
        "        text, X, target = batch\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            text = text.cuda()\r\n",
        "            X = X.cuda()\r\n",
        "            target = target.cuda()\r\n",
        "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\r\n",
        "            continue\r\n",
        "        optim.zero_grad()\r\n",
        "        prediction = model(text,X)\r\n",
        "        loss = loss_fn(prediction, target)\r\n",
        "        acc = binary_acc(prediction, target.unsqueeze(1))\r\n",
        "        loss.backward()\r\n",
        "        clip_gradient(model, 1e-1)\r\n",
        "        optim.step()\r\n",
        "        steps += 1\r\n",
        "        \r\n",
        "        if steps % 100 == 0:\r\n",
        "            print (f'Train - Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\r\n",
        "        \r\n",
        "        total_epoch_loss += loss.item()\r\n",
        "        total_epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\r\n",
        "\r\n",
        "def eval_model(model, val_iter):\r\n",
        "    total_epoch_loss = 0\r\n",
        "    total_epoch_acc = 0\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for idx, batch in enumerate(val_iter):\r\n",
        "            text, X, target = batch\r\n",
        "            if (text.size()[0] is not 32):\r\n",
        "                continue\r\n",
        "\r\n",
        "            if torch.cuda.is_available():\r\n",
        "              text = text.cuda()\r\n",
        "              X = X.cuda()\r\n",
        "              target = target.cuda()\r\n",
        "            prediction = model(text,X)\r\n",
        "            loss = loss_fn(prediction, target)\r\n",
        "            acc = binary_acc(prediction, target.unsqueeze(1))\r\n",
        "            total_epoch_loss += loss.item()\r\n",
        "            total_epoch_acc += acc.item()\r\n",
        "\r\n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)\r\n",
        "\t\r\n",
        "\r\n",
        "learning_rate = 2e-5\r\n",
        "batch_size = 32\r\n",
        "output_size = 1\r\n",
        "hidden_size = 256\r\n",
        "embedding_length = 300\r\n",
        "word_embeddings = 300\r\n",
        "vocab_size = len(word_index)\r\n",
        "\r\n",
        "model = AttentionModel(batch_size, output_size, hidden_size, vocab_size, embedding_length, embedding_matrix)\r\n",
        "loss_fn = nn.BCEWithLogitsLoss()\r\n",
        "\r\n",
        "for epoch in range(10):\r\n",
        "    train_loss, train_acc = train_model(model, train_dataloader, epoch)\r\n",
        "    val_loss, val_acc = eval_model(model, val_dataloader)\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\r\n",
        "    break\r\n",
        "    \r\n",
        "# test_loss, test_acc = eval_model(model, val_dataloader)\r\n",
        "# print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\r\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-fb8097442483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-fb8097442483>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_iter, epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    630\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2580\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32])) must be the same as input size (torch.Size([32, 1]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxhbzCtSjxP5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}