{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-Training and Testing",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmbiTyga/Task-Stylumia/blob/Basic/Model-Training_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASqB2wYxxZQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd08bf7-efc3-47e2-e2e6-769eb51e7041"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/AmbiTyga/Task-Stylumia/Basic/TrainTest.7z"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-28 18:54:51--  https://raw.githubusercontent.com/AmbiTyga/Task-Stylumia/Basic/TrainTest.7z\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9147130 (8.7M) [application/octet-stream]\n",
            "Saving to: ‘TrainTest.7z.1’\n",
            "\n",
            "TrainTest.7z.1      100%[===================>]   8.72M  56.5MB/s    in 0.2s    \n",
            "\n",
            "2021-02-28 18:54:52 (56.5 MB/s) - ‘TrainTest.7z.1’ saved [9147130/9147130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh4t8ETbx_u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9bb85b-4c0e-4e56-9b7b-a43387558c69"
      },
      "source": [
        "!7z x TrainTest.7z"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 9147130 bytes (8933 KiB)\n",
            "\n",
            "Extracting archive: TrainTest.7z\n",
            "--\n",
            "Path = TrainTest.7z\n",
            "Type = 7z\n",
            "Physical Size = 9147130\n",
            "Headers Size = 194\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     ./test_parsed.json\n",
            "  Size:     32684461 bytes (32 MiB)\n",
            "  Modified: 2021-02-28 06:10:23\n",
            "with the file from archive:\n",
            "  Path:     test_parsed.json\n",
            "  Size:     32684461 bytes (32 MiB)\n",
            "  Modified: 2021-02-28 06:10:23\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psECtCenyDMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "722606ab-8763-49a1-d909-ed3ed67ee5d9"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import torch \r\n",
        "from torchtext import data\r\n",
        "from torchtext.vocab import GloVe\r\n",
        "import torch.nn as nn\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "STOPWORDS = stopwords.words('english')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0geNMvkiCZx"
      },
      "source": [
        "train = pd.read_json('/content/train_parsed.json')\r\n",
        "test = pd.read_json('/content/test_parsed.json')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtN8oszHIFjg"
      },
      "source": [
        "def padding(text,attr = 'title'):\r\n",
        "  max_len = 39 if attr=='title' else 282\r\n",
        "  sent_len = len(text.split())\r\n",
        "  if sent_len>max_len:\r\n",
        "    return \" \".join(text.split()[:max_len])\r\n",
        "  else:\r\n",
        "    text = \" \".join(text.split()+['<pad>']*(max_len-sent_len))\r\n",
        "    return text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFhq5ommic5S"
      },
      "source": [
        "train.drop(columns=['tld_with_tok', 'ac_tok','title_tok', 'body_tok', 'text', 'raw_text'],inplace = True)\r\n",
        "test.drop(columns=['tld_with_tok', 'ac_tok','title_tok', 'body_tok', 'text', 'raw_text'],inplace = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLlhvwrpOr5F"
      },
      "source": [
        "train['text'] = '<tld> '+ train['tld']+ ' <ac> ' + train['alchemy_category'] + ' <title> ' + train['title'].apply(padding)+ ' <body> ' + train['body'].apply(padding,attr='body') \r\n",
        "test['text'] = '<tld> '+ test['tld']+ ' <ac> ' + test['alchemy_category'] + ' <title> ' + test['title'].apply(padding)+ ' <body> ' + test['body'].apply(padding,attr='body') "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrZDvIZXL2Cj"
      },
      "source": [
        "train['text'] = train['text'].apply(lambda x: \" \".join([y for y in x.split() if y not in STOPWORDS]).lower())\r\n",
        "test['text'] = test['text'].apply(lambda x: \" \".join([y for y in x.split() if y not in STOPWORDS]).lower())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Fo08pASffw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "Train,Val = train_test_split(train,random_state = 2021,test_size = 0.2,stratify = train['label'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gth54lTdS9yd"
      },
      "source": [
        "Train.to_csv('train.csv',index= False)\r\n",
        "Val.to_csv('val.csv',index= False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ypwJeGM6B9t"
      },
      "source": [
        "!pip install pytorch-nlp -q"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xEOHd_e51a5"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWqtVkTIHU6T"
      },
      "source": [
        "import requests\r\n",
        "\r\n",
        "def download_file_from_google_drive(id, destination):\r\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\r\n",
        "\r\n",
        "    session = requests.Session()\r\n",
        "\r\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\r\n",
        "    token = get_confirm_token(response)\r\n",
        "\r\n",
        "    if token:\r\n",
        "        params = { 'id' : id, 'confirm' : token }\r\n",
        "        response = session.get(URL, params = params, stream = True)\r\n",
        "\r\n",
        "    save_response_content(response, destination)    \r\n",
        "\r\n",
        "def get_confirm_token(response):\r\n",
        "    for key, value in response.cookies.items():\r\n",
        "        if key.startswith('download_warning'):\r\n",
        "            return value\r\n",
        "\r\n",
        "    return None\r\n",
        "\r\n",
        "def save_response_content(response, destination):\r\n",
        "    CHUNK_SIZE = 32768\r\n",
        "\r\n",
        "    with open(destination, \"wb\") as f:\r\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\r\n",
        "            if chunk: # filter out keep-alive new chunks\r\n",
        "                f.write(chunk)\r\n",
        "\r\n",
        "download_file_from_google_drive('1KfiHaW7Ei31VSmi7gqfSdegTjHB8xuAm', '/content/glove.840B.300d.zip')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46HFFQavDz1Z"
      },
      "source": [
        "def load_embed(file):\r\n",
        "  '''\r\n",
        "  Loads GLoVe embeddings\r\n",
        "  file -> path to glove embeddings\r\n",
        "  load_embed(...) -> Dict()\r\n",
        "  '''\r\n",
        "  def get_coefs(word,*arr): \r\n",
        "      return word, torch.from_numpy(np.array(arr,dtype=np.float32))\r\n",
        "  \r\n",
        "  embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='utf-8'))\r\n",
        "      \r\n",
        "  return embeddings_index"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCsL94heGnfM",
        "outputId": "64a333b9-5c52-499b-8226-7f7a4f75ae0a"
      },
      "source": [
        "!unzip '/content/glove.840B.300d.zip'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.840B.300d.zip\n",
            "replace glove.840B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlmXEjokBwhf"
      },
      "source": [
        "## Bilinear Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTiirvGFjkpK"
      },
      "source": [
        "from torchnlp.encoders.text import StaticTokenizerEncoder, pad_tensor\r\n",
        "\r\n",
        "class MultiModalDataset(torch.utils.data.Dataset):\r\n",
        "  def __init__(self,data):\r\n",
        "    self.features = ['alchemy_category_score', 'alchemy_labels', 'avglinksize',\r\n",
        "       'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3',\r\n",
        "       'commonlinkratio_4', 'compression_ratio', 'embed_ratio',\r\n",
        "       'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio',\r\n",
        "       'is_news', 'lengthyLinkDomain', 'linkwordscore',\r\n",
        "       'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url',\r\n",
        "       'parametrizedLinkRatio', 'spelling_errors_ratio']\r\n",
        "    self.data = data\r\n",
        "    \r\n",
        "    self.tokenizer = StaticTokenizerEncoder(data['text'].values, tokenize=lambda s: s.split())\r\n",
        "    \r\n",
        "  def __getitem__(self,i):\r\n",
        "    text = pad_tensor(self.tokenizer.encode(self.data.loc[i,'text']),length=328)\r\n",
        "    X = self.data.loc[i,self.features].astype(float).values\r\n",
        "    y = self.data.loc[i,'label']\r\n",
        "\r\n",
        "    return text,torch.FloatTensor(X),torch.FloatTensor([y])\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUv8CgwXNou0"
      },
      "source": [
        "total_data = pd.concat([pd.read_csv('/content/train.csv'),\r\n",
        "                        pd.read_csv('/content/val.csv')],ignore_index = True)\r\n",
        "all = MultiModalDataset(total_data)\r\n",
        "word_index = all.tokenizer.token_to_index\r\n",
        "del all, total_data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdEg0wLtFr_V"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\r\n",
        "train_data = MultiModalDataset(train)\r\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,batch_size=32)\r\n",
        "\r\n",
        "val = pd.read_csv('/content/val.csv')\r\n",
        "val_data = MultiModalDataset(val)\r\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,batch_size=32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRAqsJ40P916"
      },
      "source": [
        "embeddings_index = load_embed('glove.840B.300d.txt')\r\n",
        "\r\n",
        "EMBEDDING_DIM = 300\r\n",
        "embedding_matrix = torch.zeros((len(word_index) + 1, EMBEDDING_DIM))\r\n",
        "for word, i in word_index.items():\r\n",
        "    embedding_vector = embeddings_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "        # words not found in embedding index will be all-zeros.\r\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJYK-xkSBpPh"
      },
      "source": [
        "## Bilinear Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me3RY0aGhCoy"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.nn import functional as F\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class AttentionModel(torch.nn.Module):\r\n",
        "  def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\r\n",
        "    super(AttentionModel, self).__init__()\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Arguments\r\n",
        "    ---------\r\n",
        "    batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\r\n",
        "    output_size : 2 = (pos, neg)\r\n",
        "    hidden_sie : Size of the hidden_state of the LSTM\r\n",
        "    vocab_size : Size of the vocabulary containing unique words\r\n",
        "    embedding_length : Embeddding dimension of GloVe word embeddings\r\n",
        "    weights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \r\n",
        "\r\n",
        "    --------\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.output_size = output_size\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.vocab_size = vocab_size\r\n",
        "    self.embedding_length = embedding_length\r\n",
        "\r\n",
        "    self.numerical = nn.Sequential(\r\n",
        "        nn.Linear(21,64),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(64,128),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.BatchNorm1d(128),\r\n",
        "        nn.Linear(128,128),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(128,64),\r\n",
        "        nn.ReLU()\r\n",
        "    )\r\n",
        "    \r\n",
        "    self.bilinear = nn.Bilinear(64,64,96)\r\n",
        "    self.dropout = nn.Dropout(0.45)\r\n",
        "\r\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\r\n",
        "    self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\r\n",
        "    self.lstm = nn.LSTM(embedding_length, hidden_size,bidirectional = True,num_layers=4)\r\n",
        "    self.lstmNN = nn.Linear(hidden_size,128)\r\n",
        "    self.fc1 = nn.Linear(128,64)\r\n",
        "    self.Norm = nn.BatchNorm1d(96)\r\n",
        "    self.label = nn.Linear(96, output_size)\r\n",
        "    #self.attn_fc_layer = nn.Linear()\r\n",
        "    \r\n",
        "  # def attention_net(self, lstm_output, final_state):\r\n",
        "\r\n",
        "  #   \"\"\" \r\n",
        "  #   Now we will incorporate Attention mechanism in our LSTM model. In this new model, we will use attention to compute soft alignment score corresponding\r\n",
        "  #   between each of the hidden_state and the last hidden_state of the LSTM. We will be using torch.bmm for the batch matrix multiplication.\r\n",
        "\r\n",
        "  #   Arguments\r\n",
        "  #   ---------\r\n",
        "\r\n",
        "  #   lstm_output : Final output of the LSTM which contains hidden layer outputs for each sequence.\r\n",
        "  #   final_state : Final time-step hidden state (h_n) of the LSTM\r\n",
        "\r\n",
        "  #   ---------\r\n",
        "\r\n",
        "  #   Returns : It performs attention mechanism by first computing weights for each of the sequence present in lstm_output and and then finally computing the\r\n",
        "  #         new hidden state.\r\n",
        "          \r\n",
        "  #   Tensor Size :\r\n",
        "  #         hidden.size() = (batch_size, hidden_size)\r\n",
        "  #         attn_weights.size() = (batch_size, num_seq)\r\n",
        "  #         soft_attn_weights.size() = (batch_size, num_seq)\r\n",
        "  #         new_hidden_state.size() = (batch_size, hidden_size)\r\n",
        "            \r\n",
        "  #   \"\"\"\r\n",
        "\r\n",
        "  #   hidden = final_state.squeeze(0)\r\n",
        "  #   attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\r\n",
        "  #   soft_attn_weights = F.softmax(attn_weights, 1)\r\n",
        "  #   new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\r\n",
        "\r\n",
        "  #   return new_hidden_state\r\n",
        "\r\n",
        "  def forward(self, inputs,X, batch_size=None):\r\n",
        "\r\n",
        "    \"\"\" \r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    input_sentence: input_sentence of shape = (batch_size, num_sequences)\r\n",
        "    batch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    Output of the linear layer containing logits for pos & neg class which receives its input as the new_hidden_state which is basically the output of the Attention network.\r\n",
        "    final_output.shape = (batch_size, output_size)\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    input = self.word_embeddings(inputs)\r\n",
        "    # print(input.shape)\r\n",
        "    input = input.permute(1, 0, 2)\r\n",
        "    if batch_size is None:\r\n",
        "      h_0 = Variable(torch.zeros(8, self.batch_size, self.hidden_size).cuda())\r\n",
        "      c_0 = Variable(torch.zeros(8, self.batch_size, self.hidden_size).cuda())\r\n",
        "    else:\r\n",
        "      h_0 = Variable(torch.zeros(8, batch_size, self.hidden_size).cuda())\r\n",
        "      c_0 = Variable(torch.zeros(8, batch_size, self.hidden_size).cuda())\r\n",
        "      \r\n",
        "    lstm_out, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0)) # final_hidden_state.size() = (1, batch_size, hidden_size) \r\n",
        "    # output = output.permute(1, 0, 2) # output.size() = (batch_size, num_seq, hidden_size)\r\n",
        "    lstm_out = lstm_out.contiguous().view(-1, 328, 2, self.hidden_size)\r\n",
        "    # get backward output in first node\r\n",
        "    lstm_out_bw = lstm_out[:, 0, 1, :]\r\n",
        "    # get forward output in last node\r\n",
        "    lstm_out_fw = lstm_out[:, -1, 0, :]\r\n",
        "    # we may simple concatenate forward & backward outputs,\r\n",
        "    #     or add them, multiply or average; in this case i used average\r\n",
        "    lstm_out = torch.add(input=lstm_out_bw, alpha=1, other=lstm_out_fw)\r\n",
        "    lstm_out = torch.div(lstm_out, 2)\r\n",
        "    output = lstm_out.contiguous().view(-1, self.hidden_size)\r\n",
        "    # print(output.size())\r\n",
        "    attn_output = self.lstmNN(output)\r\n",
        "    attn_output = self.fc1(attn_output)\r\n",
        "    attn_output = self.dropout(attn_output)\r\n",
        "    numericals = self.numerical(X)\r\n",
        "    numericals = self.dropout(numericals)\r\n",
        "    # print((attn_output.size(), numericals.size()))\r\n",
        "    cat = self.bilinear(attn_output, numericals)\r\n",
        "    cat = self.Norm(cat)\r\n",
        "    logits = self.label(cat)\r\n",
        "    logits = F.sigmoid(logits)\r\n",
        "\r\n",
        "    return logits"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG0BdgsahJ4q",
        "outputId": "4ef9e8ee-5406-49e1-9b03-59a6d932f054"
      },
      "source": [
        "def clip_gradient(model, clip_value):\r\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\r\n",
        "    for p in params:\r\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\r\n",
        "\r\n",
        "def binary_acc(logits, targets):\r\n",
        "  corrects = (torch.max(logits, 1)[1].view(targets.size()).data == targets.data).sum()\r\n",
        "  return corrects.item() * (100.0 / targets.size(0))\r\n",
        "    \r\n",
        "def train_model(model, train_iter, epoch):\r\n",
        "    total_epoch_loss = 0\r\n",
        "    total_epoch_acc = 0\r\n",
        "    model.cuda()\r\n",
        "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\r\n",
        "    steps = 0\r\n",
        "    model.train()\r\n",
        "    for idx, batch in enumerate(train_iter):\r\n",
        "        text, X, target = batch\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            text = text.cuda()\r\n",
        "            X = X.cuda()\r\n",
        "            target = target.cuda()\r\n",
        "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\r\n",
        "            continue\r\n",
        "        optim.zero_grad()\r\n",
        "        prediction = model(text,X)\r\n",
        "        loss = loss_fn(prediction, target)\r\n",
        "        acc = binary_acc(prediction, target.unsqueeze(1))\r\n",
        "        loss.backward()\r\n",
        "        clip_gradient(model, 1e-1)\r\n",
        "        optim.step()\r\n",
        "        steps += 1\r\n",
        "        \r\n",
        "        if steps % 10 == 0:\r\n",
        "            print (f'\\t Train - Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc: .2f}%')\r\n",
        "        \r\n",
        "        total_epoch_loss += loss.item()\r\n",
        "        total_epoch_acc += acc\r\n",
        "        \r\n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\r\n",
        "\r\n",
        "def eval_model(model, val_iter):\r\n",
        "    total_epoch_loss = 0\r\n",
        "    total_epoch_acc = 0\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for idx, batch in enumerate(val_iter):\r\n",
        "            text, X, target = batch\r\n",
        "            if (text.size()[0] is not 32):\r\n",
        "                continue\r\n",
        "\r\n",
        "            if torch.cuda.is_available():\r\n",
        "              text = text.cuda()\r\n",
        "              X = X.cuda()\r\n",
        "              target = target.cuda()\r\n",
        "            prediction = model(text,X)\r\n",
        "            loss = loss_fn(prediction, target)\r\n",
        "            acc = binary_acc(prediction, target.unsqueeze(1))\r\n",
        "            total_epoch_loss += loss.item()\r\n",
        "            total_epoch_acc += acc\r\n",
        "\r\n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)\r\n",
        "\t\r\n",
        "\r\n",
        "learning_rate = 2e-5\r\n",
        "batch_size = 32\r\n",
        "output_size = 1\r\n",
        "hidden_size = 256\r\n",
        "embedding_length = 300\r\n",
        "word_embeddings = 300\r\n",
        "vocab_size = len(word_index)\r\n",
        "\r\n",
        "model = AttentionModel(batch_size, output_size, hidden_size, vocab_size, embedding_length, embedding_matrix)\r\n",
        "loss_fn = nn.BCEWithLogitsLoss()\r\n",
        "\r\n",
        "for epoch in range(50):\r\n",
        "    train_loss, train_acc = train_model(model, train_dataloader, epoch)\r\n",
        "    val_loss, val_acc = eval_model(model, val_dataloader)\r\n",
        "    \r\n",
        "    print(f\"Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}% \\n{90*'='}\")\r\n",
        "    \r\n",
        "# test_loss, test_acc = eval_model(model, val_dataloader)\r\n",
        "# print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Train - Epoch: 1, Idx: 10, Training Loss: 0.7872, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 1, Idx: 20, Training Loss: 0.6889, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 1, Idx: 30, Training Loss: 0.6834, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 1, Idx: 40, Training Loss: 0.6950, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 1, Idx: 50, Training Loss: 0.7061, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 1, Idx: 60, Training Loss: 0.6948, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 1, Idx: 70, Training Loss: 0.7814, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 1, Idx: 80, Training Loss: 0.7183, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 1, Idx: 90, Training Loss: 0.6742, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 1, Idx: 100, Training Loss: 0.7432, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 1, Idx: 110, Training Loss: 0.6042, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 1, Idx: 120, Training Loss: 0.6185, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 1, Idx: 130, Training Loss: 0.6864, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 1, Idx: 140, Training Loss: 0.6181, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 1, Idx: 150, Training Loss: 0.6978, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 1, Idx: 160, Training Loss: 0.6888, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 1, Idx: 170, Training Loss: 0.6457, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 1, Idx: 180, Training Loss: 0.7048, Training Accuracy:  56.25%\n",
            "Epoch: 01, Train Loss: 0.689, Train Acc: 48.26%, Val. Loss: 0.676379, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 2, Idx: 10, Training Loss: 0.7166, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 2, Idx: 20, Training Loss: 0.7109, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 2, Idx: 30, Training Loss: 0.6488, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 2, Idx: 40, Training Loss: 0.6858, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 2, Idx: 50, Training Loss: 0.6659, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 2, Idx: 60, Training Loss: 0.7199, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 2, Idx: 70, Training Loss: 0.7576, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 2, Idx: 80, Training Loss: 0.6798, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 2, Idx: 90, Training Loss: 0.7403, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 2, Idx: 100, Training Loss: 0.7315, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 2, Idx: 110, Training Loss: 0.6351, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 2, Idx: 120, Training Loss: 0.6069, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 2, Idx: 130, Training Loss: 0.6912, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 2, Idx: 140, Training Loss: 0.6510, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 2, Idx: 150, Training Loss: 0.6782, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 2, Idx: 160, Training Loss: 0.6815, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 2, Idx: 170, Training Loss: 0.6351, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 2, Idx: 180, Training Loss: 0.7161, Training Accuracy:  56.25%\n",
            "Epoch: 02, Train Loss: 0.683, Train Acc: 48.26%, Val. Loss: 0.677388, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 3, Idx: 10, Training Loss: 0.7180, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 3, Idx: 20, Training Loss: 0.7039, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 3, Idx: 30, Training Loss: 0.6456, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 3, Idx: 40, Training Loss: 0.6715, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 3, Idx: 50, Training Loss: 0.6824, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 3, Idx: 60, Training Loss: 0.6744, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 3, Idx: 70, Training Loss: 0.7082, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 3, Idx: 80, Training Loss: 0.6807, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 3, Idx: 90, Training Loss: 0.6311, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 3, Idx: 100, Training Loss: 0.7677, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 3, Idx: 110, Training Loss: 0.6142, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 3, Idx: 120, Training Loss: 0.6279, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 3, Idx: 130, Training Loss: 0.7099, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 3, Idx: 140, Training Loss: 0.6480, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 3, Idx: 150, Training Loss: 0.6809, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 3, Idx: 160, Training Loss: 0.7278, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 3, Idx: 170, Training Loss: 0.6090, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 3, Idx: 180, Training Loss: 0.6893, Training Accuracy:  56.25%\n",
            "Epoch: 03, Train Loss: 0.678, Train Acc: 48.26%, Val. Loss: 0.673456, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 4, Idx: 10, Training Loss: 0.6925, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 4, Idx: 20, Training Loss: 0.6580, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 4, Idx: 30, Training Loss: 0.6518, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 4, Idx: 40, Training Loss: 0.6424, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 4, Idx: 50, Training Loss: 0.6602, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 4, Idx: 60, Training Loss: 0.6532, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 4, Idx: 70, Training Loss: 0.7097, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 4, Idx: 80, Training Loss: 0.6874, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 4, Idx: 90, Training Loss: 0.6220, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 4, Idx: 100, Training Loss: 0.7199, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 4, Idx: 110, Training Loss: 0.6254, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 4, Idx: 120, Training Loss: 0.6199, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 4, Idx: 130, Training Loss: 0.7259, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 4, Idx: 140, Training Loss: 0.6214, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 4, Idx: 150, Training Loss: 0.6487, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 4, Idx: 160, Training Loss: 0.7276, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 4, Idx: 170, Training Loss: 0.6219, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 4, Idx: 180, Training Loss: 0.6991, Training Accuracy:  56.25%\n",
            "Epoch: 04, Train Loss: 0.674, Train Acc: 48.26%, Val. Loss: 0.665762, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 5, Idx: 10, Training Loss: 0.6885, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 5, Idx: 20, Training Loss: 0.6322, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 5, Idx: 30, Training Loss: 0.6568, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 5, Idx: 40, Training Loss: 0.6621, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 5, Idx: 50, Training Loss: 0.6713, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 5, Idx: 60, Training Loss: 0.6960, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 5, Idx: 70, Training Loss: 0.6971, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 5, Idx: 80, Training Loss: 0.6828, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 5, Idx: 90, Training Loss: 0.6550, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 5, Idx: 100, Training Loss: 0.7275, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 5, Idx: 110, Training Loss: 0.6126, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 5, Idx: 120, Training Loss: 0.6117, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 5, Idx: 130, Training Loss: 0.6825, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 5, Idx: 140, Training Loss: 0.6036, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 5, Idx: 150, Training Loss: 0.6443, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 5, Idx: 160, Training Loss: 0.7041, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 5, Idx: 170, Training Loss: 0.6172, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 5, Idx: 180, Training Loss: 0.6888, Training Accuracy:  56.25%\n",
            "Epoch: 05, Train Loss: 0.672, Train Acc: 48.26%, Val. Loss: 0.663848, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 6, Idx: 10, Training Loss: 0.6907, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 6, Idx: 20, Training Loss: 0.6019, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 6, Idx: 30, Training Loss: 0.6529, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 6, Idx: 40, Training Loss: 0.6341, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 6, Idx: 50, Training Loss: 0.6893, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 6, Idx: 60, Training Loss: 0.6913, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 6, Idx: 70, Training Loss: 0.7279, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 6, Idx: 80, Training Loss: 0.6825, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 6, Idx: 90, Training Loss: 0.6533, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 6, Idx: 100, Training Loss: 0.7352, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 6, Idx: 110, Training Loss: 0.6201, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 6, Idx: 120, Training Loss: 0.6147, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 6, Idx: 130, Training Loss: 0.6943, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 6, Idx: 140, Training Loss: 0.6029, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 6, Idx: 150, Training Loss: 0.6504, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 6, Idx: 160, Training Loss: 0.7582, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 6, Idx: 170, Training Loss: 0.6145, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 6, Idx: 180, Training Loss: 0.6698, Training Accuracy:  56.25%\n",
            "Epoch: 06, Train Loss: 0.669, Train Acc: 48.26%, Val. Loss: 0.662241, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 7, Idx: 10, Training Loss: 0.6694, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 7, Idx: 20, Training Loss: 0.6412, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 7, Idx: 30, Training Loss: 0.6642, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 7, Idx: 40, Training Loss: 0.6497, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 7, Idx: 50, Training Loss: 0.6809, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 7, Idx: 60, Training Loss: 0.7014, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 7, Idx: 70, Training Loss: 0.7211, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 7, Idx: 80, Training Loss: 0.7149, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 7, Idx: 90, Training Loss: 0.6396, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 7, Idx: 100, Training Loss: 0.7390, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 7, Idx: 110, Training Loss: 0.6289, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 7, Idx: 120, Training Loss: 0.6273, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 7, Idx: 130, Training Loss: 0.6667, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 7, Idx: 140, Training Loss: 0.6308, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 7, Idx: 150, Training Loss: 0.6785, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 7, Idx: 160, Training Loss: 0.7135, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 7, Idx: 170, Training Loss: 0.6224, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 7, Idx: 180, Training Loss: 0.6891, Training Accuracy:  56.25%\n",
            "Epoch: 07, Train Loss: 0.672, Train Acc: 48.26%, Val. Loss: 0.667789, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 8, Idx: 10, Training Loss: 0.6974, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 8, Idx: 20, Training Loss: 0.6343, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 8, Idx: 30, Training Loss: 0.6509, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 8, Idx: 40, Training Loss: 0.6562, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 8, Idx: 50, Training Loss: 0.6538, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 8, Idx: 60, Training Loss: 0.6870, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 8, Idx: 70, Training Loss: 0.7339, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 8, Idx: 80, Training Loss: 0.6861, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 8, Idx: 90, Training Loss: 0.6190, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 8, Idx: 100, Training Loss: 0.7529, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 8, Idx: 110, Training Loss: 0.6353, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 8, Idx: 120, Training Loss: 0.6212, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 8, Idx: 130, Training Loss: 0.6657, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 8, Idx: 140, Training Loss: 0.6418, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 8, Idx: 150, Training Loss: 0.6699, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 8, Idx: 160, Training Loss: 0.7166, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 8, Idx: 170, Training Loss: 0.6135, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 8, Idx: 180, Training Loss: 0.6832, Training Accuracy:  56.25%\n",
            "Epoch: 08, Train Loss: 0.669, Train Acc: 48.26%, Val. Loss: 0.660583, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 9, Idx: 10, Training Loss: 0.6688, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 9, Idx: 20, Training Loss: 0.6048, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 9, Idx: 30, Training Loss: 0.6358, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 9, Idx: 40, Training Loss: 0.6682, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 9, Idx: 50, Training Loss: 0.6465, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 9, Idx: 60, Training Loss: 0.6813, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 9, Idx: 70, Training Loss: 0.6930, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 9, Idx: 80, Training Loss: 0.6574, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 9, Idx: 90, Training Loss: 0.6135, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 9, Idx: 100, Training Loss: 0.7598, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 9, Idx: 110, Training Loss: 0.6369, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 9, Idx: 120, Training Loss: 0.6274, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 9, Idx: 130, Training Loss: 0.6680, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 9, Idx: 140, Training Loss: 0.6174, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 9, Idx: 150, Training Loss: 0.6483, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 9, Idx: 160, Training Loss: 0.7069, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 9, Idx: 170, Training Loss: 0.6281, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 9, Idx: 180, Training Loss: 0.7081, Training Accuracy:  56.25%\n",
            "Epoch: 09, Train Loss: 0.665, Train Acc: 48.26%, Val. Loss: 0.656544, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 10, Idx: 10, Training Loss: 0.6742, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 10, Idx: 20, Training Loss: 0.6175, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 10, Idx: 30, Training Loss: 0.6468, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 10, Idx: 40, Training Loss: 0.6449, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 10, Idx: 50, Training Loss: 0.6479, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 10, Idx: 60, Training Loss: 0.6989, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 10, Idx: 70, Training Loss: 0.7063, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 10, Idx: 80, Training Loss: 0.6698, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 10, Idx: 90, Training Loss: 0.6135, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 10, Idx: 100, Training Loss: 0.7403, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 10, Idx: 110, Training Loss: 0.6544, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 10, Idx: 120, Training Loss: 0.6124, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 10, Idx: 130, Training Loss: 0.6824, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 10, Idx: 140, Training Loss: 0.6333, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 10, Idx: 150, Training Loss: 0.6850, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 10, Idx: 160, Training Loss: 0.7070, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 10, Idx: 170, Training Loss: 0.6069, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 10, Idx: 180, Training Loss: 0.6879, Training Accuracy:  56.25%\n",
            "Epoch: 10, Train Loss: 0.665, Train Acc: 48.26%, Val. Loss: 0.666818, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 11, Idx: 10, Training Loss: 0.6962, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 11, Idx: 20, Training Loss: 0.5659, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 11, Idx: 30, Training Loss: 0.6476, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 11, Idx: 40, Training Loss: 0.6545, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 11, Idx: 50, Training Loss: 0.6344, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 11, Idx: 60, Training Loss: 0.6334, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 11, Idx: 70, Training Loss: 0.6924, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 11, Idx: 80, Training Loss: 0.7015, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 11, Idx: 90, Training Loss: 0.6506, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 11, Idx: 100, Training Loss: 0.7670, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 11, Idx: 110, Training Loss: 0.6609, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 11, Idx: 120, Training Loss: 0.6163, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 11, Idx: 130, Training Loss: 0.6955, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 11, Idx: 140, Training Loss: 0.6249, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 11, Idx: 150, Training Loss: 0.6553, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 11, Idx: 160, Training Loss: 0.6606, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 11, Idx: 170, Training Loss: 0.6407, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 11, Idx: 180, Training Loss: 0.6713, Training Accuracy:  56.25%\n",
            "Epoch: 11, Train Loss: 0.659, Train Acc: 48.26%, Val. Loss: 0.667370, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 12, Idx: 10, Training Loss: 0.6808, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 12, Idx: 20, Training Loss: 0.5680, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 12, Idx: 30, Training Loss: 0.6420, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 12, Idx: 40, Training Loss: 0.6194, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 12, Idx: 50, Training Loss: 0.6536, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 12, Idx: 60, Training Loss: 0.6818, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 12, Idx: 70, Training Loss: 0.6817, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 12, Idx: 80, Training Loss: 0.6601, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 12, Idx: 90, Training Loss: 0.6218, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 12, Idx: 100, Training Loss: 0.7249, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 12, Idx: 110, Training Loss: 0.6179, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 12, Idx: 120, Training Loss: 0.6130, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 12, Idx: 130, Training Loss: 0.6617, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 12, Idx: 140, Training Loss: 0.6266, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 12, Idx: 150, Training Loss: 0.6271, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 12, Idx: 160, Training Loss: 0.6763, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 12, Idx: 170, Training Loss: 0.6092, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 12, Idx: 180, Training Loss: 0.6751, Training Accuracy:  56.25%\n",
            "Epoch: 12, Train Loss: 0.653, Train Acc: 48.26%, Val. Loss: 0.671122, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 13, Idx: 10, Training Loss: 0.6562, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 13, Idx: 20, Training Loss: 0.6186, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 13, Idx: 30, Training Loss: 0.6104, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 13, Idx: 40, Training Loss: 0.6403, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 13, Idx: 50, Training Loss: 0.6364, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 13, Idx: 60, Training Loss: 0.6314, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 13, Idx: 70, Training Loss: 0.6900, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 13, Idx: 80, Training Loss: 0.6429, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 13, Idx: 90, Training Loss: 0.6165, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 13, Idx: 100, Training Loss: 0.6918, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 13, Idx: 110, Training Loss: 0.6421, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 13, Idx: 120, Training Loss: 0.6342, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 13, Idx: 130, Training Loss: 0.6787, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 13, Idx: 140, Training Loss: 0.5873, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 13, Idx: 150, Training Loss: 0.6330, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 13, Idx: 160, Training Loss: 0.6527, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 13, Idx: 170, Training Loss: 0.6008, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 13, Idx: 180, Training Loss: 0.6706, Training Accuracy:  56.25%\n",
            "Epoch: 13, Train Loss: 0.650, Train Acc: 48.26%, Val. Loss: 0.695801, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 14, Idx: 10, Training Loss: 0.6864, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 14, Idx: 20, Training Loss: 0.5983, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 14, Idx: 30, Training Loss: 0.6069, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 14, Idx: 40, Training Loss: 0.6201, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 14, Idx: 50, Training Loss: 0.6003, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 14, Idx: 60, Training Loss: 0.6254, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 14, Idx: 70, Training Loss: 0.6984, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 14, Idx: 80, Training Loss: 0.6554, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 14, Idx: 90, Training Loss: 0.6246, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 14, Idx: 100, Training Loss: 0.7031, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 14, Idx: 110, Training Loss: 0.6279, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 14, Idx: 120, Training Loss: 0.6069, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 14, Idx: 130, Training Loss: 0.6638, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 14, Idx: 140, Training Loss: 0.5630, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 14, Idx: 150, Training Loss: 0.6351, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 14, Idx: 160, Training Loss: 0.6667, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 14, Idx: 170, Training Loss: 0.6030, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 14, Idx: 180, Training Loss: 0.6555, Training Accuracy:  56.25%\n",
            "Epoch: 14, Train Loss: 0.643, Train Acc: 48.26%, Val. Loss: 0.667812, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 15, Idx: 10, Training Loss: 0.6629, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 15, Idx: 20, Training Loss: 0.6018, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 15, Idx: 30, Training Loss: 0.6074, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 15, Idx: 40, Training Loss: 0.6119, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 15, Idx: 50, Training Loss: 0.5895, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 15, Idx: 60, Training Loss: 0.6230, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 15, Idx: 70, Training Loss: 0.6737, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 15, Idx: 80, Training Loss: 0.6526, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 15, Idx: 90, Training Loss: 0.6043, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 15, Idx: 100, Training Loss: 0.6870, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 15, Idx: 110, Training Loss: 0.6316, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 15, Idx: 120, Training Loss: 0.6302, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 15, Idx: 130, Training Loss: 0.6695, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 15, Idx: 140, Training Loss: 0.6063, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 15, Idx: 150, Training Loss: 0.6476, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 15, Idx: 160, Training Loss: 0.6525, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 15, Idx: 170, Training Loss: 0.6021, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 15, Idx: 180, Training Loss: 0.6800, Training Accuracy:  56.25%\n",
            "Epoch: 15, Train Loss: 0.640, Train Acc: 48.26%, Val. Loss: 0.670343, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 16, Idx: 10, Training Loss: 0.6589, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 16, Idx: 20, Training Loss: 0.5961, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 16, Idx: 30, Training Loss: 0.6275, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 16, Idx: 40, Training Loss: 0.6228, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 16, Idx: 50, Training Loss: 0.5959, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 16, Idx: 60, Training Loss: 0.6327, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 16, Idx: 70, Training Loss: 0.6690, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 16, Idx: 80, Training Loss: 0.6492, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 16, Idx: 90, Training Loss: 0.6108, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 16, Idx: 100, Training Loss: 0.6761, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 16, Idx: 110, Training Loss: 0.6465, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 16, Idx: 120, Training Loss: 0.5634, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 16, Idx: 130, Training Loss: 0.6524, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 16, Idx: 140, Training Loss: 0.5866, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 16, Idx: 150, Training Loss: 0.6254, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 16, Idx: 160, Training Loss: 0.6401, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 16, Idx: 170, Training Loss: 0.5893, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 16, Idx: 180, Training Loss: 0.6369, Training Accuracy:  56.25%\n",
            "Epoch: 16, Train Loss: 0.634, Train Acc: 48.26%, Val. Loss: 0.669137, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 17, Idx: 10, Training Loss: 0.6470, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 17, Idx: 20, Training Loss: 0.5866, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 17, Idx: 30, Training Loss: 0.5886, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 17, Idx: 40, Training Loss: 0.6201, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 17, Idx: 50, Training Loss: 0.5921, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 17, Idx: 60, Training Loss: 0.6314, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 17, Idx: 70, Training Loss: 0.6960, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 17, Idx: 80, Training Loss: 0.6448, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 17, Idx: 90, Training Loss: 0.6071, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 17, Idx: 100, Training Loss: 0.6680, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 17, Idx: 110, Training Loss: 0.6432, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 17, Idx: 120, Training Loss: 0.5998, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 17, Idx: 130, Training Loss: 0.6391, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 17, Idx: 140, Training Loss: 0.5862, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 17, Idx: 150, Training Loss: 0.6465, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 17, Idx: 160, Training Loss: 0.6721, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 17, Idx: 170, Training Loss: 0.5848, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 17, Idx: 180, Training Loss: 0.6526, Training Accuracy:  56.25%\n",
            "Epoch: 17, Train Loss: 0.630, Train Acc: 48.26%, Val. Loss: 0.675645, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 18, Idx: 10, Training Loss: 0.6825, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 18, Idx: 20, Training Loss: 0.5745, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 18, Idx: 30, Training Loss: 0.6109, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 18, Idx: 40, Training Loss: 0.6026, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 18, Idx: 50, Training Loss: 0.5862, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 18, Idx: 60, Training Loss: 0.5964, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 18, Idx: 70, Training Loss: 0.6628, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 18, Idx: 80, Training Loss: 0.6761, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 18, Idx: 90, Training Loss: 0.5956, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 18, Idx: 100, Training Loss: 0.6532, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 18, Idx: 110, Training Loss: 0.6295, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 18, Idx: 120, Training Loss: 0.6212, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 18, Idx: 130, Training Loss: 0.6302, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 18, Idx: 140, Training Loss: 0.6189, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 18, Idx: 150, Training Loss: 0.6229, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 18, Idx: 160, Training Loss: 0.6451, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 18, Idx: 170, Training Loss: 0.5775, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 18, Idx: 180, Training Loss: 0.6690, Training Accuracy:  56.25%\n",
            "Epoch: 18, Train Loss: 0.628, Train Acc: 48.26%, Val. Loss: 0.677317, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 19, Idx: 10, Training Loss: 0.6614, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 19, Idx: 20, Training Loss: 0.5381, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 19, Idx: 30, Training Loss: 0.6013, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 19, Idx: 40, Training Loss: 0.6146, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 19, Idx: 50, Training Loss: 0.6035, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 19, Idx: 60, Training Loss: 0.6481, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 19, Idx: 70, Training Loss: 0.6647, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 19, Idx: 80, Training Loss: 0.6194, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 19, Idx: 90, Training Loss: 0.6253, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 19, Idx: 100, Training Loss: 0.6422, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 19, Idx: 110, Training Loss: 0.6126, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 19, Idx: 120, Training Loss: 0.6338, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 19, Idx: 130, Training Loss: 0.6713, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 19, Idx: 140, Training Loss: 0.5450, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 19, Idx: 150, Training Loss: 0.6262, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 19, Idx: 160, Training Loss: 0.5998, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 19, Idx: 170, Training Loss: 0.6217, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 19, Idx: 180, Training Loss: 0.6494, Training Accuracy:  56.25%\n",
            "Epoch: 19, Train Loss: 0.623, Train Acc: 48.26%, Val. Loss: 0.684105, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 20, Idx: 10, Training Loss: 0.6525, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 20, Idx: 20, Training Loss: 0.5694, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 20, Idx: 30, Training Loss: 0.6091, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 20, Idx: 40, Training Loss: 0.5849, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 20, Idx: 50, Training Loss: 0.5871, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 20, Idx: 60, Training Loss: 0.6078, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 20, Idx: 70, Training Loss: 0.6678, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 20, Idx: 80, Training Loss: 0.6288, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 20, Idx: 90, Training Loss: 0.5929, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 20, Idx: 100, Training Loss: 0.6699, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 20, Idx: 110, Training Loss: 0.6152, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 20, Idx: 120, Training Loss: 0.5964, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 20, Idx: 130, Training Loss: 0.6276, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 20, Idx: 140, Training Loss: 0.5883, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 20, Idx: 150, Training Loss: 0.6288, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 20, Idx: 160, Training Loss: 0.6402, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 20, Idx: 170, Training Loss: 0.5870, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 20, Idx: 180, Training Loss: 0.6556, Training Accuracy:  56.25%\n",
            "Epoch: 20, Train Loss: 0.624, Train Acc: 48.26%, Val. Loss: 0.677487, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 21, Idx: 10, Training Loss: 0.6366, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 21, Idx: 20, Training Loss: 0.5667, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 21, Idx: 30, Training Loss: 0.5740, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 21, Idx: 40, Training Loss: 0.5962, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 21, Idx: 50, Training Loss: 0.5956, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 21, Idx: 60, Training Loss: 0.6031, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 21, Idx: 70, Training Loss: 0.6516, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 21, Idx: 80, Training Loss: 0.6429, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 21, Idx: 90, Training Loss: 0.6047, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 21, Idx: 100, Training Loss: 0.6638, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 21, Idx: 110, Training Loss: 0.6077, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 21, Idx: 120, Training Loss: 0.6062, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 21, Idx: 130, Training Loss: 0.6237, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 21, Idx: 140, Training Loss: 0.6253, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 21, Idx: 150, Training Loss: 0.6496, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 21, Idx: 160, Training Loss: 0.6265, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 21, Idx: 170, Training Loss: 0.6038, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 21, Idx: 180, Training Loss: 0.6777, Training Accuracy:  56.25%\n",
            "Epoch: 21, Train Loss: 0.620, Train Acc: 48.26%, Val. Loss: 0.679658, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 22, Idx: 10, Training Loss: 0.6419, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 22, Idx: 20, Training Loss: 0.5375, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 22, Idx: 30, Training Loss: 0.5733, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 22, Idx: 40, Training Loss: 0.6337, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 22, Idx: 50, Training Loss: 0.5860, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 22, Idx: 60, Training Loss: 0.6001, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 22, Idx: 70, Training Loss: 0.6702, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 22, Idx: 80, Training Loss: 0.6185, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 22, Idx: 90, Training Loss: 0.5898, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 22, Idx: 100, Training Loss: 0.6550, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 22, Idx: 110, Training Loss: 0.6021, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 22, Idx: 120, Training Loss: 0.5902, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 22, Idx: 130, Training Loss: 0.5860, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 22, Idx: 140, Training Loss: 0.5428, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 22, Idx: 150, Training Loss: 0.6327, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 22, Idx: 160, Training Loss: 0.6102, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 22, Idx: 170, Training Loss: 0.5985, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 22, Idx: 180, Training Loss: 0.7180, Training Accuracy:  56.25%\n",
            "Epoch: 22, Train Loss: 0.615, Train Acc: 48.26%, Val. Loss: 0.663447, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 23, Idx: 10, Training Loss: 0.6489, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 23, Idx: 20, Training Loss: 0.6216, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 23, Idx: 30, Training Loss: 0.5784, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 23, Idx: 40, Training Loss: 0.6074, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 23, Idx: 50, Training Loss: 0.5882, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 23, Idx: 60, Training Loss: 0.5983, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 23, Idx: 70, Training Loss: 0.6556, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 23, Idx: 80, Training Loss: 0.6808, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 23, Idx: 90, Training Loss: 0.6056, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 23, Idx: 100, Training Loss: 0.6307, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 23, Idx: 110, Training Loss: 0.5991, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 23, Idx: 120, Training Loss: 0.5965, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 23, Idx: 130, Training Loss: 0.6208, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 23, Idx: 140, Training Loss: 0.5837, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 23, Idx: 150, Training Loss: 0.5767, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 23, Idx: 160, Training Loss: 0.6031, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 23, Idx: 170, Training Loss: 0.5855, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 23, Idx: 180, Training Loss: 0.6892, Training Accuracy:  56.25%\n",
            "Epoch: 23, Train Loss: 0.613, Train Acc: 48.26%, Val. Loss: 0.685227, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 24, Idx: 10, Training Loss: 0.6322, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 24, Idx: 20, Training Loss: 0.5447, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 24, Idx: 30, Training Loss: 0.5833, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 24, Idx: 40, Training Loss: 0.6065, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 24, Idx: 50, Training Loss: 0.5616, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 24, Idx: 60, Training Loss: 0.5924, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 24, Idx: 70, Training Loss: 0.6795, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 24, Idx: 80, Training Loss: 0.6323, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 24, Idx: 90, Training Loss: 0.5814, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 24, Idx: 100, Training Loss: 0.6664, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 24, Idx: 110, Training Loss: 0.5742, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 24, Idx: 120, Training Loss: 0.5803, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 24, Idx: 130, Training Loss: 0.5836, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 24, Idx: 140, Training Loss: 0.5624, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 24, Idx: 150, Training Loss: 0.5822, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 24, Idx: 160, Training Loss: 0.5998, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 24, Idx: 170, Training Loss: 0.5760, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 24, Idx: 180, Training Loss: 0.6845, Training Accuracy:  56.25%\n",
            "Epoch: 24, Train Loss: 0.603, Train Acc: 48.26%, Val. Loss: 0.690825, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 25, Idx: 10, Training Loss: 0.5948, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 25, Idx: 20, Training Loss: 0.5513, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 25, Idx: 30, Training Loss: 0.5665, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 25, Idx: 40, Training Loss: 0.5969, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 25, Idx: 50, Training Loss: 0.5595, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 25, Idx: 60, Training Loss: 0.5690, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 25, Idx: 70, Training Loss: 0.6272, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 25, Idx: 80, Training Loss: 0.6734, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 25, Idx: 90, Training Loss: 0.5629, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 25, Idx: 100, Training Loss: 0.6418, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 25, Idx: 110, Training Loss: 0.5858, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 25, Idx: 120, Training Loss: 0.5634, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 25, Idx: 130, Training Loss: 0.5852, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 25, Idx: 140, Training Loss: 0.5737, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 25, Idx: 150, Training Loss: 0.5845, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 25, Idx: 160, Training Loss: 0.6221, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 25, Idx: 170, Training Loss: 0.5623, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 25, Idx: 180, Training Loss: 0.6552, Training Accuracy:  56.25%\n",
            "Epoch: 25, Train Loss: 0.596, Train Acc: 48.26%, Val. Loss: 0.687136, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 26, Idx: 10, Training Loss: 0.6017, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 26, Idx: 20, Training Loss: 0.5396, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 26, Idx: 30, Training Loss: 0.5530, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 26, Idx: 40, Training Loss: 0.5773, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 26, Idx: 50, Training Loss: 0.5686, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 26, Idx: 60, Training Loss: 0.5628, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 26, Idx: 70, Training Loss: 0.6358, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 26, Idx: 80, Training Loss: 0.6436, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 26, Idx: 90, Training Loss: 0.5891, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 26, Idx: 100, Training Loss: 0.6530, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 26, Idx: 110, Training Loss: 0.5839, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 26, Idx: 120, Training Loss: 0.5626, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 26, Idx: 130, Training Loss: 0.5646, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 26, Idx: 140, Training Loss: 0.6697, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 26, Idx: 150, Training Loss: 0.5704, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 26, Idx: 160, Training Loss: 0.6268, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 26, Idx: 170, Training Loss: 0.5496, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 26, Idx: 180, Training Loss: 0.6624, Training Accuracy:  56.25%\n",
            "Epoch: 26, Train Loss: 0.599, Train Acc: 48.26%, Val. Loss: 0.680161, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 27, Idx: 10, Training Loss: 0.6142, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 27, Idx: 20, Training Loss: 0.5800, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 27, Idx: 30, Training Loss: 0.5678, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 27, Idx: 40, Training Loss: 0.5800, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 27, Idx: 50, Training Loss: 0.5594, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 27, Idx: 60, Training Loss: 0.5842, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 27, Idx: 70, Training Loss: 0.6220, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 27, Idx: 80, Training Loss: 0.6360, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 27, Idx: 90, Training Loss: 0.6000, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 27, Idx: 100, Training Loss: 0.6793, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 27, Idx: 110, Training Loss: 0.5704, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 27, Idx: 120, Training Loss: 0.5515, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 27, Idx: 130, Training Loss: 0.6281, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 27, Idx: 140, Training Loss: 0.5397, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 27, Idx: 150, Training Loss: 0.6164, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 27, Idx: 160, Training Loss: 0.6381, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 27, Idx: 170, Training Loss: 0.6199, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 27, Idx: 180, Training Loss: 0.6608, Training Accuracy:  56.25%\n",
            "Epoch: 27, Train Loss: 0.597, Train Acc: 48.26%, Val. Loss: 0.685703, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 28, Idx: 10, Training Loss: 0.6037, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 28, Idx: 20, Training Loss: 0.5507, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 28, Idx: 30, Training Loss: 0.5671, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 28, Idx: 40, Training Loss: 0.5767, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 28, Idx: 50, Training Loss: 0.5571, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 28, Idx: 60, Training Loss: 0.5693, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 28, Idx: 70, Training Loss: 0.6178, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 28, Idx: 80, Training Loss: 0.6444, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 28, Idx: 90, Training Loss: 0.5664, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 28, Idx: 100, Training Loss: 0.6413, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 28, Idx: 110, Training Loss: 0.6038, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 28, Idx: 120, Training Loss: 0.5531, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 28, Idx: 130, Training Loss: 0.5937, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 28, Idx: 140, Training Loss: 0.5356, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 28, Idx: 150, Training Loss: 0.5953, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 28, Idx: 160, Training Loss: 0.5875, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 28, Idx: 170, Training Loss: 0.5938, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 28, Idx: 180, Training Loss: 0.6726, Training Accuracy:  56.25%\n",
            "Epoch: 28, Train Loss: 0.594, Train Acc: 48.26%, Val. Loss: 0.682745, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 29, Idx: 10, Training Loss: 0.6154, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 29, Idx: 20, Training Loss: 0.5524, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 29, Idx: 30, Training Loss: 0.5626, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 29, Idx: 40, Training Loss: 0.5777, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 29, Idx: 50, Training Loss: 0.5432, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 29, Idx: 60, Training Loss: 0.5908, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 29, Idx: 70, Training Loss: 0.6241, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 29, Idx: 80, Training Loss: 0.6458, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 29, Idx: 90, Training Loss: 0.5729, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 29, Idx: 100, Training Loss: 0.6346, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 29, Idx: 110, Training Loss: 0.6003, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 29, Idx: 120, Training Loss: 0.5521, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 29, Idx: 130, Training Loss: 0.5780, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 29, Idx: 140, Training Loss: 0.5131, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 29, Idx: 150, Training Loss: 0.5734, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 29, Idx: 160, Training Loss: 0.5876, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 29, Idx: 170, Training Loss: 0.5542, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 29, Idx: 180, Training Loss: 0.6662, Training Accuracy:  56.25%\n",
            "Epoch: 29, Train Loss: 0.592, Train Acc: 48.26%, Val. Loss: 0.691351, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 30, Idx: 10, Training Loss: 0.6216, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 30, Idx: 20, Training Loss: 0.5388, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 30, Idx: 30, Training Loss: 0.5625, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 30, Idx: 40, Training Loss: 0.5846, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 30, Idx: 50, Training Loss: 0.5628, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 30, Idx: 60, Training Loss: 0.5643, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 30, Idx: 70, Training Loss: 0.6294, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 30, Idx: 80, Training Loss: 0.6114, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 30, Idx: 90, Training Loss: 0.5643, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 30, Idx: 100, Training Loss: 0.6303, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 30, Idx: 110, Training Loss: 0.5749, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 30, Idx: 120, Training Loss: 0.5714, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 30, Idx: 130, Training Loss: 0.5707, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 30, Idx: 140, Training Loss: 0.5616, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 30, Idx: 150, Training Loss: 0.6012, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 30, Idx: 160, Training Loss: 0.5769, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 30, Idx: 170, Training Loss: 0.5781, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 30, Idx: 180, Training Loss: 0.6616, Training Accuracy:  56.25%\n",
            "Epoch: 30, Train Loss: 0.589, Train Acc: 48.26%, Val. Loss: 0.682404, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 31, Idx: 10, Training Loss: 0.5948, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 31, Idx: 20, Training Loss: 0.5353, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 31, Idx: 30, Training Loss: 0.5630, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 31, Idx: 40, Training Loss: 0.5600, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 31, Idx: 50, Training Loss: 0.5538, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 31, Idx: 60, Training Loss: 0.5627, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 31, Idx: 70, Training Loss: 0.6238, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 31, Idx: 80, Training Loss: 0.6537, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 31, Idx: 90, Training Loss: 0.5745, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 31, Idx: 100, Training Loss: 0.6469, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 31, Idx: 110, Training Loss: 0.6025, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 31, Idx: 120, Training Loss: 0.5398, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 31, Idx: 130, Training Loss: 0.5819, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 31, Idx: 140, Training Loss: 0.5113, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 31, Idx: 150, Training Loss: 0.5687, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 31, Idx: 160, Training Loss: 0.5701, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 31, Idx: 170, Training Loss: 0.5720, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 31, Idx: 180, Training Loss: 0.6819, Training Accuracy:  56.25%\n",
            "Epoch: 31, Train Loss: 0.592, Train Acc: 48.26%, Val. Loss: 0.689536, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 32, Idx: 10, Training Loss: 0.6079, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 32, Idx: 20, Training Loss: 0.5582, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 32, Idx: 30, Training Loss: 0.5580, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 32, Idx: 40, Training Loss: 0.5939, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 32, Idx: 50, Training Loss: 0.5722, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 32, Idx: 60, Training Loss: 0.5581, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 32, Idx: 70, Training Loss: 0.6179, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 32, Idx: 80, Training Loss: 0.6608, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 32, Idx: 90, Training Loss: 0.5490, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 32, Idx: 100, Training Loss: 0.6307, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 32, Idx: 110, Training Loss: 0.5612, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 32, Idx: 120, Training Loss: 0.5704, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 32, Idx: 130, Training Loss: 0.6045, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 32, Idx: 140, Training Loss: 0.5373, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 32, Idx: 150, Training Loss: 0.5516, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 32, Idx: 160, Training Loss: 0.5943, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 32, Idx: 170, Training Loss: 0.5221, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 32, Idx: 180, Training Loss: 0.6838, Training Accuracy:  56.25%\n",
            "Epoch: 32, Train Loss: 0.591, Train Acc: 48.26%, Val. Loss: 0.683995, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 33, Idx: 10, Training Loss: 0.6365, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 33, Idx: 20, Training Loss: 0.5625, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 33, Idx: 30, Training Loss: 0.5584, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 33, Idx: 40, Training Loss: 0.5780, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 33, Idx: 50, Training Loss: 0.5507, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 33, Idx: 60, Training Loss: 0.5627, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 33, Idx: 70, Training Loss: 0.6175, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 33, Idx: 80, Training Loss: 0.6458, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 33, Idx: 90, Training Loss: 0.5887, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 33, Idx: 100, Training Loss: 0.6351, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 33, Idx: 110, Training Loss: 0.5709, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 33, Idx: 120, Training Loss: 0.5779, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 33, Idx: 130, Training Loss: 0.6312, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 33, Idx: 140, Training Loss: 0.5105, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 33, Idx: 150, Training Loss: 0.5893, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 33, Idx: 160, Training Loss: 0.5820, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 33, Idx: 170, Training Loss: 0.5530, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 33, Idx: 180, Training Loss: 0.6567, Training Accuracy:  56.25%\n",
            "Epoch: 33, Train Loss: 0.588, Train Acc: 48.26%, Val. Loss: 0.691135, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 34, Idx: 10, Training Loss: 0.6321, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 34, Idx: 20, Training Loss: 0.5473, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 34, Idx: 30, Training Loss: 0.5390, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 34, Idx: 40, Training Loss: 0.5833, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 34, Idx: 50, Training Loss: 0.5620, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 34, Idx: 60, Training Loss: 0.6017, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 34, Idx: 70, Training Loss: 0.6235, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 34, Idx: 80, Training Loss: 0.6309, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 34, Idx: 90, Training Loss: 0.5623, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 34, Idx: 100, Training Loss: 0.6392, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 34, Idx: 110, Training Loss: 0.5422, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 34, Idx: 120, Training Loss: 0.5530, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 34, Idx: 130, Training Loss: 0.5753, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 34, Idx: 140, Training Loss: 0.5530, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 34, Idx: 150, Training Loss: 0.5921, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 34, Idx: 160, Training Loss: 0.5960, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 34, Idx: 170, Training Loss: 0.5186, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 34, Idx: 180, Training Loss: 0.6444, Training Accuracy:  56.25%\n",
            "Epoch: 34, Train Loss: 0.585, Train Acc: 48.26%, Val. Loss: 0.685147, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 35, Idx: 10, Training Loss: 0.6265, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 35, Idx: 20, Training Loss: 0.5387, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 35, Idx: 30, Training Loss: 0.5392, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 35, Idx: 40, Training Loss: 0.5996, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 35, Idx: 50, Training Loss: 0.5909, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 35, Idx: 60, Training Loss: 0.5739, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 35, Idx: 70, Training Loss: 0.6157, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 35, Idx: 80, Training Loss: 0.6101, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 35, Idx: 90, Training Loss: 0.5638, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 35, Idx: 100, Training Loss: 0.6177, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 35, Idx: 110, Training Loss: 0.5601, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 35, Idx: 120, Training Loss: 0.5757, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 35, Idx: 130, Training Loss: 0.6096, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 35, Idx: 140, Training Loss: 0.5183, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 35, Idx: 150, Training Loss: 0.5522, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 35, Idx: 160, Training Loss: 0.5898, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 35, Idx: 170, Training Loss: 0.5551, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 35, Idx: 180, Training Loss: 0.6532, Training Accuracy:  56.25%\n",
            "Epoch: 35, Train Loss: 0.581, Train Acc: 48.26%, Val. Loss: 0.685374, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 36, Idx: 10, Training Loss: 0.6258, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 36, Idx: 20, Training Loss: 0.5389, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 36, Idx: 30, Training Loss: 0.5585, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 36, Idx: 40, Training Loss: 0.5829, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 36, Idx: 50, Training Loss: 0.5739, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 36, Idx: 60, Training Loss: 0.5869, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 36, Idx: 70, Training Loss: 0.6110, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 36, Idx: 80, Training Loss: 0.6284, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 36, Idx: 90, Training Loss: 0.5589, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 36, Idx: 100, Training Loss: 0.6189, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 36, Idx: 110, Training Loss: 0.5750, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 36, Idx: 120, Training Loss: 0.5389, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 36, Idx: 130, Training Loss: 0.5819, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 36, Idx: 140, Training Loss: 0.5226, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 36, Idx: 150, Training Loss: 0.5629, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 36, Idx: 160, Training Loss: 0.5738, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 36, Idx: 170, Training Loss: 0.5279, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 36, Idx: 180, Training Loss: 0.6502, Training Accuracy:  56.25%\n",
            "Epoch: 36, Train Loss: 0.582, Train Acc: 48.26%, Val. Loss: 0.698665, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 37, Idx: 10, Training Loss: 0.6192, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 37, Idx: 20, Training Loss: 0.5269, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 37, Idx: 30, Training Loss: 0.5507, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 37, Idx: 40, Training Loss: 0.5736, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 37, Idx: 50, Training Loss: 0.5547, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 37, Idx: 60, Training Loss: 0.5912, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 37, Idx: 70, Training Loss: 0.6301, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 37, Idx: 80, Training Loss: 0.6371, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 37, Idx: 90, Training Loss: 0.6130, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 37, Idx: 100, Training Loss: 0.6295, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 37, Idx: 110, Training Loss: 0.5463, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 37, Idx: 120, Training Loss: 0.6049, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 37, Idx: 130, Training Loss: 0.5645, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 37, Idx: 140, Training Loss: 0.5357, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 37, Idx: 150, Training Loss: 0.5485, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 37, Idx: 160, Training Loss: 0.5825, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 37, Idx: 170, Training Loss: 0.5502, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 37, Idx: 180, Training Loss: 0.6695, Training Accuracy:  56.25%\n",
            "Epoch: 37, Train Loss: 0.582, Train Acc: 48.26%, Val. Loss: 0.694633, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 38, Idx: 10, Training Loss: 0.6258, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 38, Idx: 20, Training Loss: 0.5600, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 38, Idx: 30, Training Loss: 0.5529, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 38, Idx: 40, Training Loss: 0.5821, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 38, Idx: 50, Training Loss: 0.5393, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 38, Idx: 60, Training Loss: 0.5725, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 38, Idx: 70, Training Loss: 0.6058, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 38, Idx: 80, Training Loss: 0.6176, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 38, Idx: 90, Training Loss: 0.5608, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 38, Idx: 100, Training Loss: 0.6295, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 38, Idx: 110, Training Loss: 0.5733, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 38, Idx: 120, Training Loss: 0.5489, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 38, Idx: 130, Training Loss: 0.5827, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 38, Idx: 140, Training Loss: 0.5111, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 38, Idx: 150, Training Loss: 0.5380, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 38, Idx: 160, Training Loss: 0.5831, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 38, Idx: 170, Training Loss: 0.5269, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 38, Idx: 180, Training Loss: 0.6441, Training Accuracy:  56.25%\n",
            "Epoch: 38, Train Loss: 0.581, Train Acc: 48.26%, Val. Loss: 0.688313, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 39, Idx: 10, Training Loss: 0.6182, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 39, Idx: 20, Training Loss: 0.5270, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 39, Idx: 30, Training Loss: 0.5513, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 39, Idx: 40, Training Loss: 0.5712, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 39, Idx: 50, Training Loss: 0.5499, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 39, Idx: 60, Training Loss: 0.5651, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 39, Idx: 70, Training Loss: 0.6101, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 39, Idx: 80, Training Loss: 0.6188, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 39, Idx: 90, Training Loss: 0.5515, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 39, Idx: 100, Training Loss: 0.6276, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 39, Idx: 110, Training Loss: 0.5575, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 39, Idx: 120, Training Loss: 0.5388, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 39, Idx: 130, Training Loss: 0.5776, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 39, Idx: 140, Training Loss: 0.5194, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 39, Idx: 150, Training Loss: 0.5618, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 39, Idx: 160, Training Loss: 0.6177, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 39, Idx: 170, Training Loss: 0.5190, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 39, Idx: 180, Training Loss: 0.6251, Training Accuracy:  56.25%\n",
            "Epoch: 39, Train Loss: 0.577, Train Acc: 48.26%, Val. Loss: 0.695287, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 40, Idx: 10, Training Loss: 0.5984, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 40, Idx: 20, Training Loss: 0.5296, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 40, Idx: 30, Training Loss: 0.5521, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 40, Idx: 40, Training Loss: 0.5753, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 40, Idx: 50, Training Loss: 0.5269, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 40, Idx: 60, Training Loss: 0.5628, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 40, Idx: 70, Training Loss: 0.6246, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 40, Idx: 80, Training Loss: 0.5974, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 40, Idx: 90, Training Loss: 0.5540, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 40, Idx: 100, Training Loss: 0.6176, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 40, Idx: 110, Training Loss: 0.5471, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 40, Idx: 120, Training Loss: 0.5628, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 40, Idx: 130, Training Loss: 0.5698, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 40, Idx: 140, Training Loss: 0.5233, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 40, Idx: 150, Training Loss: 0.5391, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 40, Idx: 160, Training Loss: 0.6103, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 40, Idx: 170, Training Loss: 0.5205, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 40, Idx: 180, Training Loss: 0.6420, Training Accuracy:  56.25%\n",
            "Epoch: 40, Train Loss: 0.574, Train Acc: 48.26%, Val. Loss: 0.699283, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 41, Idx: 10, Training Loss: 0.6125, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 41, Idx: 20, Training Loss: 0.5545, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 41, Idx: 30, Training Loss: 0.5584, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 41, Idx: 40, Training Loss: 0.5706, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 41, Idx: 50, Training Loss: 0.5369, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 41, Idx: 60, Training Loss: 0.5712, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 41, Idx: 70, Training Loss: 0.6198, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 41, Idx: 80, Training Loss: 0.6132, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 41, Idx: 90, Training Loss: 0.5620, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 41, Idx: 100, Training Loss: 0.6185, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 41, Idx: 110, Training Loss: 0.5795, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 41, Idx: 120, Training Loss: 0.5478, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 41, Idx: 130, Training Loss: 0.5819, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 41, Idx: 140, Training Loss: 0.5267, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 41, Idx: 150, Training Loss: 0.6102, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 41, Idx: 160, Training Loss: 0.5957, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 41, Idx: 170, Training Loss: 0.5096, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 41, Idx: 180, Training Loss: 0.6615, Training Accuracy:  56.25%\n",
            "Epoch: 41, Train Loss: 0.577, Train Acc: 48.26%, Val. Loss: 0.701631, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 42, Idx: 10, Training Loss: 0.5882, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 42, Idx: 20, Training Loss: 0.5388, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 42, Idx: 30, Training Loss: 0.5507, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 42, Idx: 40, Training Loss: 0.5703, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 42, Idx: 50, Training Loss: 0.5396, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 42, Idx: 60, Training Loss: 0.5626, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 42, Idx: 70, Training Loss: 0.6305, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 42, Idx: 80, Training Loss: 0.6054, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 42, Idx: 90, Training Loss: 0.5494, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 42, Idx: 100, Training Loss: 0.6176, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 42, Idx: 110, Training Loss: 0.5659, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 42, Idx: 120, Training Loss: 0.5388, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 42, Idx: 130, Training Loss: 0.5826, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 42, Idx: 140, Training Loss: 0.5201, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 42, Idx: 150, Training Loss: 0.5273, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 42, Idx: 160, Training Loss: 0.6147, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 42, Idx: 170, Training Loss: 0.5320, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 42, Idx: 180, Training Loss: 0.6380, Training Accuracy:  56.25%\n",
            "Epoch: 42, Train Loss: 0.575, Train Acc: 48.26%, Val. Loss: 0.686953, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 43, Idx: 10, Training Loss: 0.5864, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 43, Idx: 20, Training Loss: 0.5577, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 43, Idx: 30, Training Loss: 0.5557, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 43, Idx: 40, Training Loss: 0.5700, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 43, Idx: 50, Training Loss: 0.5270, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 43, Idx: 60, Training Loss: 0.5576, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 43, Idx: 70, Training Loss: 0.6225, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 43, Idx: 80, Training Loss: 0.6160, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 43, Idx: 90, Training Loss: 0.5542, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 43, Idx: 100, Training Loss: 0.6330, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 43, Idx: 110, Training Loss: 0.5577, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 43, Idx: 120, Training Loss: 0.5388, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 43, Idx: 130, Training Loss: 0.5642, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 43, Idx: 140, Training Loss: 0.5124, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 43, Idx: 150, Training Loss: 0.5707, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 43, Idx: 160, Training Loss: 0.6250, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 43, Idx: 170, Training Loss: 0.5322, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 43, Idx: 180, Training Loss: 0.6581, Training Accuracy:  56.25%\n",
            "Epoch: 43, Train Loss: 0.572, Train Acc: 48.26%, Val. Loss: 0.692714, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 44, Idx: 10, Training Loss: 0.5873, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 44, Idx: 20, Training Loss: 0.5386, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 44, Idx: 30, Training Loss: 0.5390, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 44, Idx: 40, Training Loss: 0.5732, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 44, Idx: 50, Training Loss: 0.5445, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 44, Idx: 60, Training Loss: 0.5647, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 44, Idx: 70, Training Loss: 0.6369, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 44, Idx: 80, Training Loss: 0.6147, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 44, Idx: 90, Training Loss: 0.5395, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 44, Idx: 100, Training Loss: 0.6288, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 44, Idx: 110, Training Loss: 0.5482, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 44, Idx: 120, Training Loss: 0.5388, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 44, Idx: 130, Training Loss: 0.5817, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 44, Idx: 140, Training Loss: 0.5053, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 44, Idx: 150, Training Loss: 0.5158, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 44, Idx: 160, Training Loss: 0.5997, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 44, Idx: 170, Training Loss: 0.5476, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 44, Idx: 180, Training Loss: 0.6516, Training Accuracy:  56.25%\n",
            "Epoch: 44, Train Loss: 0.573, Train Acc: 48.26%, Val. Loss: 0.692468, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 45, Idx: 10, Training Loss: 0.5891, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 45, Idx: 20, Training Loss: 0.5269, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 45, Idx: 30, Training Loss: 0.5499, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 45, Idx: 40, Training Loss: 0.5785, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 45, Idx: 50, Training Loss: 0.5399, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 45, Idx: 60, Training Loss: 0.5801, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 45, Idx: 70, Training Loss: 0.6336, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 45, Idx: 80, Training Loss: 0.6290, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 45, Idx: 90, Training Loss: 0.5270, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 45, Idx: 100, Training Loss: 0.6176, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 45, Idx: 110, Training Loss: 0.5377, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 45, Idx: 120, Training Loss: 0.5390, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 45, Idx: 130, Training Loss: 0.5877, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 45, Idx: 140, Training Loss: 0.5226, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 45, Idx: 150, Training Loss: 0.5270, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 45, Idx: 160, Training Loss: 0.5999, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 45, Idx: 170, Training Loss: 0.5468, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 45, Idx: 180, Training Loss: 0.6257, Training Accuracy:  56.25%\n",
            "Epoch: 45, Train Loss: 0.573, Train Acc: 48.26%, Val. Loss: 0.699831, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 46, Idx: 10, Training Loss: 0.6078, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 46, Idx: 20, Training Loss: 0.5253, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 46, Idx: 30, Training Loss: 0.5481, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 46, Idx: 40, Training Loss: 0.5628, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 46, Idx: 50, Training Loss: 0.5464, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 46, Idx: 60, Training Loss: 0.5626, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 46, Idx: 70, Training Loss: 0.6251, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 46, Idx: 80, Training Loss: 0.6060, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 46, Idx: 90, Training Loss: 0.5489, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 46, Idx: 100, Training Loss: 0.6176, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 46, Idx: 110, Training Loss: 0.5339, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 46, Idx: 120, Training Loss: 0.5450, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 46, Idx: 130, Training Loss: 0.5814, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 46, Idx: 140, Training Loss: 0.5107, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 46, Idx: 150, Training Loss: 0.5410, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 46, Idx: 160, Training Loss: 0.5642, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 46, Idx: 170, Training Loss: 0.5287, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 46, Idx: 180, Training Loss: 0.6665, Training Accuracy:  56.25%\n",
            "Epoch: 46, Train Loss: 0.572, Train Acc: 48.26%, Val. Loss: 0.690887, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 47, Idx: 10, Training Loss: 0.5764, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 47, Idx: 20, Training Loss: 0.5273, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 47, Idx: 30, Training Loss: 0.5469, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 47, Idx: 40, Training Loss: 0.5746, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 47, Idx: 50, Training Loss: 0.5330, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 47, Idx: 60, Training Loss: 0.5508, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 47, Idx: 70, Training Loss: 0.6252, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 47, Idx: 80, Training Loss: 0.5935, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 47, Idx: 90, Training Loss: 0.5534, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 47, Idx: 100, Training Loss: 0.6184, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 47, Idx: 110, Training Loss: 0.5345, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 47, Idx: 120, Training Loss: 0.5613, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 47, Idx: 130, Training Loss: 0.5818, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 47, Idx: 140, Training Loss: 0.5460, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 47, Idx: 150, Training Loss: 0.5359, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 47, Idx: 160, Training Loss: 0.5802, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 47, Idx: 170, Training Loss: 0.5610, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 47, Idx: 180, Training Loss: 0.6465, Training Accuracy:  56.25%\n",
            "Epoch: 47, Train Loss: 0.572, Train Acc: 48.26%, Val. Loss: 0.697532, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 48, Idx: 10, Training Loss: 0.6191, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 48, Idx: 20, Training Loss: 0.5274, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 48, Idx: 30, Training Loss: 0.5390, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 48, Idx: 40, Training Loss: 0.5891, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 48, Idx: 50, Training Loss: 0.5277, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 48, Idx: 60, Training Loss: 0.5609, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 48, Idx: 70, Training Loss: 0.6264, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 48, Idx: 80, Training Loss: 0.6257, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 48, Idx: 90, Training Loss: 0.5392, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 48, Idx: 100, Training Loss: 0.6176, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 48, Idx: 110, Training Loss: 0.5379, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 48, Idx: 120, Training Loss: 0.5506, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 48, Idx: 130, Training Loss: 0.5824, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 48, Idx: 140, Training Loss: 0.5183, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 48, Idx: 150, Training Loss: 0.5632, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 48, Idx: 160, Training Loss: 0.5872, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 48, Idx: 170, Training Loss: 0.5543, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 48, Idx: 180, Training Loss: 0.6198, Training Accuracy:  56.25%\n",
            "Epoch: 48, Train Loss: 0.571, Train Acc: 48.26%, Val. Loss: 0.687841, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 49, Idx: 10, Training Loss: 0.5938, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 49, Idx: 20, Training Loss: 0.5283, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 49, Idx: 30, Training Loss: 0.5407, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 49, Idx: 40, Training Loss: 0.5746, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 49, Idx: 50, Training Loss: 0.5656, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 49, Idx: 60, Training Loss: 0.5513, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 49, Idx: 70, Training Loss: 0.6274, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 49, Idx: 80, Training Loss: 0.5938, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 49, Idx: 90, Training Loss: 0.5351, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 49, Idx: 100, Training Loss: 0.6212, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 49, Idx: 110, Training Loss: 0.5414, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 49, Idx: 120, Training Loss: 0.5310, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 49, Idx: 130, Training Loss: 0.5894, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 49, Idx: 140, Training Loss: 0.4999, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 49, Idx: 150, Training Loss: 0.5400, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 49, Idx: 160, Training Loss: 0.5806, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 49, Idx: 170, Training Loss: 0.5463, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 49, Idx: 180, Training Loss: 0.6159, Training Accuracy:  56.25%\n",
            "Epoch: 49, Train Loss: 0.571, Train Acc: 48.26%, Val. Loss: 0.692554, Val. Acc: 47.74% \n",
            "==========================================================================================\n",
            "\t Train - Epoch: 50, Idx: 10, Training Loss: 0.6042, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 50, Idx: 20, Training Loss: 0.5580, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 50, Idx: 30, Training Loss: 0.5693, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 50, Idx: 40, Training Loss: 0.5702, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 50, Idx: 50, Training Loss: 0.5376, Training Accuracy:  46.88%\n",
            "\t Train - Epoch: 50, Idx: 60, Training Loss: 0.5647, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 50, Idx: 70, Training Loss: 0.6367, Training Accuracy:  59.38%\n",
            "\t Train - Epoch: 50, Idx: 80, Training Loss: 0.6057, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 50, Idx: 90, Training Loss: 0.5275, Training Accuracy:  50.00%\n",
            "\t Train - Epoch: 50, Idx: 100, Training Loss: 0.6250, Training Accuracy:  62.50%\n",
            "\t Train - Epoch: 50, Idx: 110, Training Loss: 0.5403, Training Accuracy:  34.38%\n",
            "\t Train - Epoch: 50, Idx: 120, Training Loss: 0.5280, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 50, Idx: 130, Training Loss: 0.5701, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 50, Idx: 140, Training Loss: 0.5061, Training Accuracy:  25.00%\n",
            "\t Train - Epoch: 50, Idx: 150, Training Loss: 0.5347, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 50, Idx: 160, Training Loss: 0.5639, Training Accuracy:  53.12%\n",
            "\t Train - Epoch: 50, Idx: 170, Training Loss: 0.5256, Training Accuracy:  43.75%\n",
            "\t Train - Epoch: 50, Idx: 180, Training Loss: 0.6027, Training Accuracy:  56.25%\n",
            "Epoch: 50, Train Loss: 0.568, Train Acc: 48.26%, Val. Loss: 0.690335, Val. Acc: 47.74% \n",
            "==========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxhbzCtSjxP5"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}